#!/usr/bin/env python3
"""
üöÄ Open WebUI Manager
Interactive CLI to manage Open WebUI: restart, rebuild, run fix IP script, and update API keys.
"""

import curses
import subprocess
import os
import sys
import shutil  # for locating local Ollama CLI binary

ENV_FILE = os.path.join(os.getcwd(), ".env")
FIX_IP_SCRIPT = os.path.join(os.getcwd(), "fix_ip_address.sh")

MENU = [
    "üîÑ Restart Open WebUI",
    "üõ†Ô∏è  Rebuild & Deploy Open WebUI",
    "üåê Fix IP Address",
    "üîë Update API Keys (.env)",
    "üêô Manage Ollama Models",
    "üö™ Exit",
]


def run_command(cmd):
    try:
        subprocess.run(cmd, shell=False, check=False)
    except Exception as e:
        print(f"Error running {cmd}: {e}")
        input("Press Enter to continue...")


def update_api_keys():
    curses.endwin()
    # Load existing .env or create
    env = {}
    if os.path.exists(ENV_FILE):
        with open(ENV_FILE) as f:
            for line in f:
                if '=' in line and not line.strip().startswith('#'):
                    k,v = line.strip().split('=',1)
                    env[k] = v
    else:
        open(ENV_FILE, 'a').close()
    print("\n=== Update API Keys (.env) ===")
    print("Available keys:")
    for k in sorted(env.keys()):
        print(f"  ‚Ä¢ {k}")
    key = input("Enter the key to update (or new key): ").strip()
    val = input(f"Enter new value for {key}: ").strip()
    env[key] = val
    # Write back
    with open(ENV_FILE, 'w') as f:
        for k, v in env.items():
            f.write(f"{k}={v}\n")
    print(f"Updated {key} in .env")
    input("Press Enter to return to menu...")


# Helper to determine how to invoke the Ollama CLI: check for Docker container first, then local binary
def get_ollama_cmd():
    # If a Docker container named 'ollama' is running, use it
    try:
        result = subprocess.run(
            ["docker", "ps", "--filter", "name=ollama", "--format", "{{.Names}}"],
            capture_output=True, text=True, check=False
        )
        names = result.stdout.strip().splitlines()
        if "ollama" in names:
            return ["docker", "exec", "ollama", "ollama"]
    except Exception:
        pass
    # Fallback to local Ollama CLI if installed via Homebrew
    if shutil.which("ollama"):
        return ["ollama"]
    # No Ollama CLI found
    print("‚ö†Ô∏è  Ollama CLI not found. Please install via Homebrew: brew install ollama")
    sys.exit(1)


# New function to manage pulling and deleting Ollama models
def manage_ollama_models():
    # Safely end curses mode if initialized
    try:
        curses.endwin()
    except curses.error:
        pass
    # Determine how to call Ollama (docker container or local binary)
    base_cmd = get_ollama_cmd()
    while True:
        print("\n=== üêô Manage Ollama Models ===")
        print("1. üîÑ Pull a model from Ollama.com")
        print("2. ü§ñ Pull a model from HuggingFace.co")
        print("3. üóëÔ∏è Delete an existing Ollama model")
        print("4. ‚Ü©Ô∏è Return to main menu")
        choice = input("Enter choice [1-4]: ").strip()
        if choice == "1":
            model = input("Enter model name to pull from Ollama.com: ").strip()
            run_command(base_cmd + ["pull", model])
        elif choice == "2":
            model = input("Enter HuggingFace model path (org/model) to pull: ").strip()
            full = f"hf.co/{model}"
            run_command(base_cmd + ["pull", full])
        elif choice == "3":
            try:
                output = subprocess.check_output(base_cmd + ["list"], text=True)
                lines = output.splitlines()[1:]
                models = [line.split()[0] for line in lines]
                if not models:
                    print("No Ollama models found.")
                else:
                    print("\nInstalled Ollama models:")
                    for idx, m in enumerate(models):
                        print(f"  {idx+1}. {m}")
                    sel = input("Enter number of model to delete: ").strip()
                    if sel.isdigit() and 1 <= int(sel) <= len(models):
                        to_delete = models[int(sel)-1]
                        run_command(base_cmd + ["rm", to_delete])
                    else:
                        print("Invalid selection.")
            except Exception as e:
                print(f"Error listing models: {e}")
        elif choice == "4":
            break
        else:
            print("Invalid selection.")
        input("Press Enter to continue...")


def main(stdscr):
    curses.curs_set(0)
    curses.init_pair(1, curses.COLOR_BLACK, curses.COLOR_CYAN)
    h, w = stdscr.getmaxyx()
    current = 0
    while True:
        stdscr.clear()
        title = "üõ°Ô∏è  Open WebUI Manager"
        stdscr.attron(curses.A_BOLD)
        stdscr.addstr(1, w//2 - len(title)//2, title)
        stdscr.attroff(curses.A_BOLD)
        for idx, item in enumerate(MENU):
            x = 4
            y = idx + 4
            if idx == current:
                stdscr.attron(curses.color_pair(1))
                stdscr.addstr(y, x, item)
                stdscr.attroff(curses.color_pair(1))
            else:
                stdscr.addstr(y, x, item)
        key = stdscr.getch()
        if key == curses.KEY_UP and current > 0:
            current -= 1
        elif key == curses.KEY_DOWN and current < len(MENU) - 1:
            current += 1
        elif key in [curses.KEY_ENTER, ord("\n")]:
            stdscr.clear()
            stdscr.refresh()
            if current == 0:
                run_command(["docker", "compose", "restart", "open-webui"] )
            elif current == 1:
                run_command(["docker", "compose", "up", "--build", "-d"] )
            elif current == 2:
                run_command([FIX_IP_SCRIPT])
            elif current == 3:
                update_api_keys()
            elif current == 4:
                manage_ollama_models()
            elif current == 5:
                break
        stdscr.refresh()

if __name__ == "__main__":
    # If called with 'ollama', directly run the Ollama model management menu
    if len(sys.argv) > 1 and sys.argv[1] == "ollama":
        manage_ollama_models()
        sys.exit(0)
    try:
        curses.wrapper(main)
    except Exception as e:
        print(f"Fatal error: {e}")
        sys.exit(1) 